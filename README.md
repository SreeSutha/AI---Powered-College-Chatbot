# AI Powered Collge Chatbot

Searching for College related information on general search engines like Google can 
sometimes yield overwhelming or irrelevant results, making it challenging to find specific 
and reliable academic resources. Additionally, it might be time-consuming to select through 
large amounts of information. Chatbots can provide targeted and relevant information 
tailored to the user's specific query, saving time and effort. A chat robot is computer software 
with Artificial Intelligence that can simulate a conversation using textual or audio 
techniques. This could be a text-based (typed) conversation, a spoken conversation, or even 
a non-verbal conversation. Chatbots can run on local computers and phones, though most of 
the time they are accessed through the internet. A chatbot is typically perceived as an 
engaging software entity that humans can talk to. It can be interesting, inspiring, and 
intriguing. Natural language processing enables a bot to converse in the most natural manner 
possible. The best user-chatbot interaction is a well-balanced mix of innovative technology 
and human intervention. This project is to create a chatbot for Sri Sarada College. Using a 
specialized recurrent neural network (LSTM—Long Short Term Memory), it will select a 
random response from a list of responses. RNNs are designed to handle text. This project 
presents a simplified approach to achieve this purpose using some basic deep Learning 
packages like Tensor Flow, Keras, Keras_nighty, Scipy, nltk, and Numpy. (SGD) Stochastic 
Gradient Descent is an optimization algorithm that can be used to train neural network 
models. The Stochastic Gradient Descent "mini-batch" algorithm requires gradients to be 
calculated for each variable in the model so that new values for the variables can be 
calculated. Flask has a simple and intuitive API that allows developers to quickly build web 
applications. It does not impose strict programming patterns or architectural choices, giving 
developers the freedom to structure their applications as they see fit. Speech recognition also 
adds. It can be really challenging to discover the right question to ask on the internet, but 
this chatbot will respond with an acceptable and relevant answer. The main objective is to 
implement an online chatbot system to assist users who access the college website and to 
identify answers related to user-submitted questions.

Keras Nightly (2.5.0. dev2021032900):
Keras is a high-level neural networks API. The nightly version provides the latest 
features and updates. Keras Nightly (2.5.0. dev2021032900) is a development version of the 
Keras library, which is a high-level neural networks API. Nightly versions of software 
typically represent the latest and most cutting-edge updates and features that developers are 
actively working on. In this specific package, the version number '2.5.0. dev2021032900' 
indicates that it's a development build leading up to the release of Keras version 2.5.0. Users 
who opt for nightly builds like this are often interested in experimenting with the very latest 
features and improvements in the library, although it's important to note that these versions 
might not be as stable as official release versions. Developers and researchers often use nightly 
builds to stay at the forefront of deep learning advancements and contribute to testing and 
feedback before the final release.
TensorFlow (2.5.0):
TensorFlow is an open-source machine learning framework developed by Google. It's 
widely used for building and training neural networks. TensorFlow is a robust and versatile 
open-source machine learning framework developed by Google. It has become a cornerstone 
in the field of deep learning and artificial intelligence. With its powerful capabilities for 
building, training, and deploying neural networks, TensorFlow has found applications in a 
wide range of domains, from computer vision and natural language processing to 
reinforcement learning and beyond. It offers flexibility through both high-level APIs, such as 
Keras integration, and low-level access for advanced customization. 
TensorFlow's scalability allows it to harness the power of CPUs and GPUs, making it 
suitable for projects of various scales. Its extensive ecosystem, including tools like 
TensorBoard for visualization and TensorFlow Serving for model deployment, as well as a 
strong community, makes it a top choice for researchers and developers in the machine 
learning community. 
8
NumPy (1.19.5):
NumPy is a fundamental package for scientific computing with Python. It provides 
support for arrays and matrices, essential for data manipulation. NumPy (Numerical Python) 
version 1.19.5 is a fundamental package for scientific computing in Python. It provides 
support for creating and manipulating arrays, which are the foundation for numerical 
computations in various fields such as mathematics, physics, engineering, and data science. 
NumPy's arrays are more efficient and versatile than Python lists, enabling vectorized 
operations and mathematical functions on entire arrays without the need for explicit loops. 
This package is a cornerstone of the Python scientific ecosystem and serves as the basis for 
many other libraries and tools. 
NumPy's capabilities extend beyond array manipulation to include linear algebra, 
Fourier transforms, random number generation, and integration with other data manipulation 
libraries like pandas. Its reliability, performance, and wide adoption make it an essential 
component of any data analysis or scientific computing project in Python.
NLTK (3.6.2):
NLTK (Natural Language Toolkit) is a library for working with human language data. 
It's commonly used for text processing and NLP tasks. NLTK (Natural Language Toolkit) is a 
Python package that serves as a comprehensive library for working with human language data. 
In its version 3.6.2, NLTK offers a wide range of tools and resources for various natural 
language processing (NLP) tasks. These include tokenization, stemming, lemmatization, partof-speech tagging, syntactic and semantic parsing, and sentiment analysis, among others. 
NLTK also provides access to various linguistic corpora, lexical resources, and pretrained models that are valuable for both NLP research and practical applications. Its userfriendly API and extensive documentation make it a popular choice for linguists, researchers, 
and developers working on projects involving text analysis and language understanding. 
NLTK plays a pivotal role in advancing the field of NLP by offering accessible tools 
and resources for exploring and manipulating human language data.
Keras (2.4.3):
Keras is a high-level neural networks API. This is a specific version of Keras, which 
may be used with TensorFlow as a backend. Keras (version 2.4.3) is a high-level deep learning 
9
framework that simplifies the process of building and training neural networks. It provides an 
intuitive and user-friendly API, making it particularly accessible to both beginners and 
experienced machine learning practitioners. Keras serves as an interface to underlying deep 
learning libraries such as TensorFlow, Theano, and Microsoft Cognitive Toolkit (CNTK), 
allowing users to seamlessly switch between them. With Keras, developers can define 
complex neural network architectures, including convolutional neural networks (CNNs), 
recurrent neural networks (RNNs), and more, with ease. It also supports both CPU and GPU 
acceleration, making it suitable for various hardware configurations. Keras is widely used for 
tasks like image classification, natural language processing, and reinforcement learning, and 
its integration into TensorFlow as TensorFlow.Keras has solidified its position as one of the 
leading tools in the deep learning landscape.
PyTorch:
PyTorch is an open-source machine learning framework developed by Facebook's AI 
Research lab. It's popular for deep learning tasks, especially in research. PyTorch is an opensource machine learning framework developed by Facebook's AI Research lab (FAIR). It has 
gained significant popularity in the machine learning and deep learning communities for its 
flexibility, dynamic computation graph, and ease of use. 
PyTorch is known for its intuitive and Pythonic syntax, making it a preferred choice 
for researchers and developers. It offers a wide range of tools and libraries for building and 
training neural networks, handling tensors efficiently, and optimizing deep learning models.
PyTorch is widely used in both research and production environments, and its 
seamless integration with libraries like TorchScript and PyTorch Lightning simplifies the 
deployment of machine learning models. With a vibrant community and continuous 
development, PyTorch remains at the forefront of the deep learning landscape, powering 
innovations in natural language processing, computer vision, reinforcement learning, and 
more.
Speech Recognition:
This library allows user to perform speech recognition tasks, converting spoken 
language into text. A Speech Recognition package, in the context of software development, 
refers to a collection of tools and libraries designed to convert spoken language or audio 
signals into textual data that a computer can understand and process. These packages are 
10
essential for building applications that involve voice interactions, such as virtual assistants, 
transcription services, and voice-controlled systems. They typically provide functionalities 
like audio signal processing, feature extraction, and machine learning models that can 
recognize speech patterns and convert them into text. 
Popular speech recognition packages often incorporate deep learning techniques and 
neural networks to achieve high accuracy in recognizing spoken words and phrases. These 
packages play a pivotal role in making voice-based interactions and applications more 
accessible and user-friendly across a wide range of industries, from healthcare and customer 
service to automotive and home automation.
Pygame:
Pygame is a popular and versatile Python library that is primarily used for developing 
2D games and multimedia applications. It provides a set of modules and functions that 
simplify game development, making it accessible to both beginners and experienced 
developers. Pygame handle graphics, sound, input, and collision detection, among other gamerelated tasks. Beyond game development, Pygame has found utility in creating interactive 
simulations, educational software, and multimedia presentations. Its simplicity and crossplatform compatibility make it a valuable tool for those looking to create engaging interactive 
experiences in Python. Pygame's active community and extensive documentation make it an 
excellent choice for anyone interested in delving into game development or multimedia 
programming using Python.
PyAudio:
PyAudio is a Python library for working with audio data. It's often used for tasks like 
audio recording and playback. PyAudio is a Python library that provides a simple and crossplatform way to work with audio input and output. It serves as a valuable tool for a wide range 
of applications, including voice recording, audio playback, speech recognition, and interactive 
audio processing. PyAudio is known for its ease of use and compatibility with various audio 
devices and platforms, making it an excellent choice for tasks like building voice-controlled 
applications, creating audiovisual projects, or conducting audio analysis. Its versatility,
coupled with the ability to integrate seamlessly with other Python libraries and frameworks, 
makes PyAudio a popular choice among developers and researchers for audio-related projects.
11
Flask:
Flask is a micro web framework for building web applications in Python. It's 
lightweight and suitable for small to medium-sized web projects.
Gradio:
Gradio is a Python library that simplifies the process of building and deploying 
interactive machine learning models and interfaces. It offers a user-friendly and intuitive way 
to create web-based UIs for models, allowing users to input data, visualize results, and interact 
with machine learning applications without requiring extensive web development skills. 
Gradio supports a wide range of machine learning frameworks, including TensorFlow, 
PyTorch, scikit-learn, and more, making it versatile for various types of models and tasks. 
With Gradio, developers can quickly turn their machine learning models into accessible and 
user-friendly applications, making it easier for both technical and non-technical users to 
leverage the power of AI in various domains, from image and text analysis to audio and video 
processing. Its simplicity and flexibility make it a valuable tool for prototyping, sharing, and 
deploying machine learning projects.
Hugging Face Hub:
Hugging Face provides pre-trained models and datasets for natural language 
processing. The hub is used for accessing and sharing these resources.
Matplotlib:
Matplotlib is a versatile and widely-used Python library for data visualization and 
plotting. It provides a flexible and intuitive interface for creating a wide range of static, 
animated, or interactive visualizations, making it an essential tool for data analysts, scientists, 
and engineers. With Matplotlib, users can generate high-quality charts, graphs, and plots to 
convey complex data in a visually appealing manner. It supports a variety of plot types, 
including line plots, scatter plots, bar charts, histograms, and more. Matplotlib also offers 
extensive customization options, allowing users to control every aspect of their plots, from 
colors and labels to axis scales and annotations. Its compatibility with various output formats, 
including PNG, PDF, and interactive environments like Jupyter notebooks, makes it a valuable 
asset in both academic and industry settings, enabling effective data exploration and 
communication.
12
Pandas:
Pandas is a powerful library for data manipulation and analysis, providing data 
structures and functions to work with structured data. Pandas is a Python library that serves 
as a fundamental tool for data manipulation and analysis. It provides powerful and flexible 
data structures, primarily the DataFrame and Series, which enable users to efficiently handle 
and analyze tabular data. 
Pandas excels in tasks such as data cleaning, transformation, and exploration, making 
it an essential component of the data science and data analysis toolkit. With Pandas, users can 
perform operations like filtering, grouping, aggregation, and merging data with ease. Its 
seamless integration with other Python libraries, such as NumPy and Matplotlib, allows for 
comprehensive data analysis, visualization, and reporting. Whether working with structured 
data in research, business, or any domain, Pandas simplifies the process of extracting valuable 
insights and patterns from datasets, making it an indispensable resource for data professionals 
and researchers alike.
Tokenizers:
The Tokenizers package is a critical tool in the field of natural language processing 
(NLP). It plays a fundamental role in breaking down and processing textual data into smaller 
units known as tokens. Tokenization is a crucial preprocessing step in NLP, as it helps 
transform raw text into a format that can be easily analyzed by machine learning models. The 
Tokenizers package provides a robust and efficient set of tools for various tokenization tasks, 
including word tokenization, subword tokenization, and byte-pair encoding. It is particularly 
valuable in handling languages with complex structures, morphologies, and character sets. 
With its support for different tokenization algorithms and a user-friendly interface, Tokenizers 
simplifies the task of preparing text data for tasks such as sentiment analysis, text 
classification, machine translation, and more, making it an indispensable component in the 
NLP toolbox. 
OpenAI:
OpenAI is an organization that develops AI models and technologies. Access their 
models and APIs to perform various AI tasks.
13
1.3. Recurrent Neural Networks (RNN):
Recurrent Neural Networks (RNNs) are a type of neural network architecture designed 
for processing sequences of data, such as time series, text, speech, and more. They are 
particularly well-suited for tasks where the order of the data points matters. RNNs are capable 
of processing sequences of data one element at a time while maintaining an internal hidden 
state that captures information about the sequence seen so far. 
RNNs have recurrent connections, which allow them to use information from previous 
time steps when processing the current time step. This recurrent behavior makes them suitable 
for tasks requiring memory of past information. RNNs can handle seque21nces of varying 
lengths, which is useful for tasks like natural language understanding and generation.
RNNs are commonly used in various NLP tasks, including language modeling, 
machine translation, sentiment analysis, and chatbot development. RNNs can be used to 
generate text-based responses for chatbots. Given an input message from the user, the RNN 
can generate a coherent and contextually relevant response. RNNs can be used for natural 
language understanding (NLU) in chatbots. They can process user queries and extract relevant 
information, such as intent and entities, from the text.
Figure: 1.1 – Layer of RNN
14
RNNs can help chatbots maintain a memory of the conversation history. This allows 
the chatbot to have context-aware conversations and remember user queries from previous 
turns. Sequence-to-sequence models, which use RNNs as their building blocks, are commonly 
used for chatbot applications. These models take a sequence of words as input and produce a 
sequence of words as output, making them suitable for tasks like machine translation and 
chatbot response generation. 
RNNs, combined with attention mechanisms and pre-trained language models (e.g., 
Transformers), enable the development of contextual chatbots that can understand and 
generate human-like responses based on the context of the conversation.
It's worth noting that while RNNs have been widely used for sequence-based tasks, 
more recent architectures like Transformers (e.g., BERT, GPT-3) have gained popularity in 
NLP due to their ability to capture long-range dependencies and context in text data. 
Transformers have been applied to chatbot development as well, leading to state-of-the-art 
models for natural language understanding and generation. However, RNNs remain a 
fundamental building block in many NLP pipelines and are still used in various chatbot 
implementations.
1.4. Natural Language Processing (NLP):
Natural Language Processing (NLP) is a crucial component in the development of 
chatbots. NLP techniques and tools empower chatbots to understand, process, and generate 
human language, making them effective in engaging and assisting users in natural 
conversations. NLP helps chatbots comprehend and interpret user input. It involves tasks like 
tokenization (breaking text into words or phrases), part-of-speech tagging (identifying the role 
of words in a sentence), and syntactic parsing (analyzing sentence structure). These techniques 
enable chatbots to extract meaning from user queries. 
NLP allows chatbots to determine the intent behind user messages. By employing 
techniques like intent classification, chatbots can identify whether a user is asking a question, 
making a request, expressing a sentiment, or engaging in small talk. This understanding guides 
the chatbot's response. Chatbots often need to extract specific pieces of information from user 
input, such as dates, names, locations, or product names. NLP-based entity recognition helps 
chatbots identify and tag these entities, facilitating more accurate responses. 
15
NLP can be used to gauge the sentiment of user messages. In response generation, NLP 
techniques like text generation models (e.g., GPT-3) are employed to craft coherent and 
contextually relevant responses. These models can generate human-like text and maintain the 
conversational flow.
NLP can enable chatbots to offer multilingual support by incorporating machine 
translation models. This allows chatbots to understand and respond to users in different 
languages, expanding their reach to a global audience. Chatbots can summarize lengthy text or 
provide concise answers to user queries using NLP-based summarization techniques. This is 
especially useful for condensing complex information. NLP models, such as BERT 
(Bidirectional Encoder Representations from Transformers), can be used to build chatbots that 
excel at answering questions based on a corpus of knowledge. These models can understand 
context and provide detailed responses. NLP helps identify named entities in text, such as 
people, organizations, dates, and locations. Chatbots can use this information to provide more 
accurate and context-aware responses. NLP-based chatbots maintain context across 
conversations. They remember previous messages and use this context to provide coherent and 
relevant responses. Context management is vital for natural and engaging interactions. NLP 
assists in building user profiles by analyzing historical interactions. Chatbots can use this 
information to personalize responses and offer recommendations based on user preferences.
1.5. FLASK:
Flask is a popular web framework in Python that is often used to build web applications 
and APIs. In the context of a chatbot, Flask can be used to create a web-based interface for 
the chatbot, allowing users to interact with it through a web browser or a mobile app. 
Creating a Flask application using ‘Flask(__name__)’. In Flask, routes are defined to 
specify how different URLs should be handled. When a user submits a message or a query 
through a web form or API, Flask can capture that input and pass it to the chatbot for 
processing. 
Once Flask receives the user's input, it can call the chatbot's logic to generate a 
response. This typically involves passing the user's message to the chatbot's model or function 
and getting the chatbot's response. 
16
Flask can then render a response template or return a JSON response containing the 
chatbot's reply. This response is sent back to the user's web browser or app. Flask can store 
and manage the conversation history, which includes both user messages and chatbot 
responses. This history can be useful for providing context and reference during the 
conversation.
Flask can serve as the backend for a web-based chat interface. HTML templates can 
be used to create the chat UI, and Flask can handle the dynamic updates and interactions with 
the chatbot. In addition to a web interface, Flask can also serve as an API that external 
applications can use to interact with the chatbot programmatically. This allows for integration 
with other services and platforms.
1.6. Stochastic Gradient Descent (SGD):
Stochastic Gradient Descent (SGD) is a popular optimization algorithm used in 
machine learning and deep learning to train models efficiently. It's particularly well-suited for 
large datasets and complex models. SGD is a variant of the gradient descent optimization 
algorithm. In traditional gradient descent, the model's parameters are updated based on the 
average gradient of the loss function computed over the entire dataset. While this method can 
work well, it can be computationally expensive, especially for large datasets. 
SGD addresses this issue by updating the model's parameters using the gradient of the 
loss function for a randomly chosen subset of the dataset (a single data point or a mini-batch 
of data points) at each iteration. This random selection of data points introduces a degree of 
randomness or noise into the parameter updates. SGD often leads to models that generalize 
well to unseen data, thanks to the noise-induced exploration of different parts of the parameter 
space.
Stochastic Gradient Descent (SGD) can be used in the training of chatbot models, just 
as it is applied in various other machine learning and deep learning tasks. When developing a 
chatbot, especially one based on neural networks or deep learning, employ SGD or its variants 
for optimizing the model's parameters. Many modern chatbots are built using neural network 
architectures, such as recurrent neural networks (RNNs) or transformer-based models. 
17
SGD is often used to train these neural networks. During training, the chatbot is exposed 
to a dataset containing pairs of user inputs and corresponding chatbot responses. SGD adjusts 
the neural network's weights and biases to minimize the difference between the predicted 
responses and the actual responses in the training data. Instead of using the entire training 
dataset in each training iteration, which can be computationally expensive.
Figure: 1.2. Stochastic and Gradient
SGD for chatbots typically employs mini-batch training. In this approach, a random 
subset (mini-batch) of the training data is used to compute the gradient and update the model 
parameters. This reduces the computational burden while still making progress in model 
training. Adjusting the learning rate (step size for parameter updates) is crucial for the stability 
and convergence of SGD. Learning rate scheduling techniques, such as reducing the learning 
rate over time, can help fine-tune the training process of a chatbot model. This prevents the 
model from overshooting optimal parameter values and helps it converge more effectively. 
SGD can be combined with regularization techniques, such as dropout or weight decay, 
to prevent overfitting in chatbot models. Overfitting can occur when the model becomes too 
specialized in the training data and performs poorly on unseen data. Regularization helps 
maintain model generalization. The choice of an appropriate loss function is essential. In 
chatbot development, common loss functions include cross-entropy loss for classification tasks 
(e.g., predicting the next word in a sentence) or sequence-to-sequence loss for generating 
coherent responses in a dialogue. 
18
SGD is not only used for training but also for evaluating the chatbot's performance. 
After training, SGD to fine-tune the model based on feedback from real users or perform online 
learning to adapt to changing user preferences and language patterns. SGD plays a critical role 
in training and fine-tuning chatbot models, helping them learn from data and improve their 
ability to generate meaningful and contextually relevant responses in conversations. It's an 
essential optimization technique that contributes to the effectiveness and efficiency of chatbot 
development.
1.7. Long Short-Term Memory (LSTM) :
Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) 
architecture that is commonly used in chatbot development. Chatbots need to understand the 
context of a conversation to provide meaningful responses. LSTM networks are well-suited 
for this task because they excel at processing sequential data. They can analyze a sequence of 
words in a sentence and capture dependencies between words or phrases, allowing the chatbot 
to maintain context during a conversation. LSTMs can be used in the NLU component of a 
chatbot to extract intent and entities from user input. For instance, if a user asks a question or 
makes a request, LSTM-based models can identify the relevant keywords and entities that 
guide the chatbot's response. 
Figure: 1.3 – LSTM Network
19
LSTM networks are often used in the response generation part of a chatbot. When it's 
time for the chatbot to craft a reply, the LSTM can take into account the conversation history 
and generate responses that are contextually relevant. This is especially important for 
maintaining engaging and coherent conversations. LSTM-based chatbots can be used for 
natural language generation tasks, such as creating product descriptions, news articles, or 
informative responses to user queries. LSTMs can be trained on large text corpora to generate 
human-like text.
LSTM models can analyze a user's past interactions and preferences to personalize 
responses. They can remember user-specific details and tailor responses accordingly, making 
the chatbot experience more engaging and user-centric. LSTM networks are trained using 
supervised learning, where they learn from labeled data, typically consisting of pairs of user 
inputs and corresponding chatbot responses. 
The LSTM learns to predict the next word or sequence of words in the response, given 
the input and previous conversation history. Pre-trained LSTM models, such as those based on 
transformer architectures like GPT (Generative Pre-trained Transformer), can be fine-tuned for 
chatbot-specific tasks. This allows developers to leverage the knowledge and language 
understanding capabilities of these models while adapting them to chatbot contexts. 
LSTM networks are designed to handle sequences of varying lengths, making them 
suitable for managing long conversations. They can retain and use information from earlier 
parts of the conversation when generating responses later in the dialogue.

REFERENCES
[1] Niranjan Dandekar , Suyog Ghodey,” Implementation of a Chatbot using Natural 
Language Processing”, Department Of Computer, Pimpri Chinchwad College of 
Engineering,ESHM-17 23 – December 2017.
[2] Francesco Colace, Francesco Pascale DIIn,University of Salerno Fisciano (SA), 
Italy,Antonio Ferraioli, Luca Garofalo, Alfredo Troiano System Management S.r.l.,Naples, 
Italy, Saverio Lemma, Marco LombardiSIMASLab,University of Salerno Fisciano (SA), 
Italy,” A Conversational Workflow Model for Chatbot”, · July 2017,DOI: 
10.18293/SEKE2017-208.
[3] Ali Jboor & Maher Salamin ,"Admission Chatbot",Palestine Polytechnic 
UniversityCollege of IT and Computer Engineering,May-2021.
[4] Silvia Quarteroni,Suresh Manandhar ,"A Chatbot-based Interactive Question 
Answering System", The University of York York, YO10 5DD,United Kingdom, 
suresh@cs.york.ac.uk,2019.
[5] Ujaliben Kalpesh Bavishi,"IMPLEMENTING A COLLEGE ENQUIRY CHATBOT",
Department of Computer Science California State University, Sacramento, SPRING 2019.
[6] Arijit Datta Y5111,"Contextual Flow In Chatbot Conversations", CS365, Spring 2008.
[7] Jonathan and Xin, ChunSheng (2021) "Developing an AI-Powered Chatbot to Support 
the Administration of Middle and High School Cybersecurity Camps," Journal of 
Cybersecurity Education, Research and Practice: Vol. 2021 : No. 1 , Article 6.Available at: 
https://digitalcommons.kennesaw.edu/jcerp/vol2021/iss1/6
[8] Rohit Tamrakar, Niraj Wani,Design and Development of CHATBOT: A Review, 
Mechanical Engineering Department Sardar Vallabhabhi National Institute of Technology, 
Surat –INDIA rt@med.svnit.ac.in,April 2021.
[9] Mansi Vaidya, Pratika Takitkar, Ravina Potpose and Prof. Mamta 
Balbudhe,"ARTIFICIAL INTELLIGENCE BASED COLLEGE ENQUIRY CHATBOT"eISSN: 2582-5208, International Research Journal of Modernization in Engineering Technology 
65
and Science( Peer-Reviewed, Open Access, Fully Refereed International Journal 
),Volume:05/Issue:03/March-2023,DOI : https://www.doi.org/10.56726/IRJMETS34820
[10] Vilde Molmen Host, Marte Rimer and Anna Sofie Schei," INFORMATION BASED 
CHATBOT", In5480: Specialization in research in design of IT, Autumn 2018.
[11] Nuria Haristian, Artificial Intelligence (AI) Chatbot as Language Learning Medium: 
An inquiry, Japanese Language Education Department, Universitas Pendidikan Indonesia, Jl. 
Dr. Setiabudhi 229, Bandung, Indonesia, 2018.
[12] Aishwarya Kedar, Jyoti Dahale, Khushboo Patel, Shivani Lahamag and Prof. S. G. 
Chordiya,"Chatbot System for Healthcare using Artificial Intelligence", ISSN: 2455-2631 © 
September 2020 IJSDR | Volume 5 Issue 9
[13] Munira Ansari, Saalim Shaikh, Mohammed Saad Parbulkar and Talha Khan, 
"Intelligent Chatbot", Special Issue - 2021,International Journal of Engineering Research & 
Technology (IJERT), ISSN: 2278-0181, Published by, www.ijert.org, NREST - 2021 
Conference Proceedings.
[14] Tarun Lalwani, Shashank Bhalotia, Ashish Pal, Shreya Bisen, Vasundhara 
Rathod,"Implementation of a Chatbot System using AI and NLP", International Journal of 
Innovative Research in Computer Science & Technology (IJIRCST) ISSN: 2347-5552, 
Volume-6, Issue-3, May 2018DOI: 10.21276/ijircst.2018.6.3.2
[15] Dr. Vishwanath Karad, "Research Paper on Chatbot Development for Educational 
Institute",MIT World Peace University, School of Computer Science Engineering and 
Technology, Pune, India – 411038
[16] Chokri Kooli, "Chatbots in Education and Research: A Critical Examination of Ethical 
Implications and Solutions", Sustainability 2023, 15,5614. 
https://doi.org/10.3390/su15075614, Academic Editors: Hui-Chun Chu,Di Zou and Gwo-Jen 
Hwang, Published: 23 March 2023.
[17] Dahlbaeck, A. Jonsson, and L. Ahrenberg. 1993. Wizard of Oz studies: why and how. 
In Proceedings of IUI ’93, pages 193–200, New York, NY, USA. ACM Press.
[18] De Boni and S. Manandhar. 2005. Implementing clarification dialogue in open-domain 
question an- swering. Nat. Lang. Eng., 11.
66
[19] Ginzburg, 1996. Interrogatives: Questions, Facts and Dialogue. Blackwell, Oxford.
[20] Hickl and S. Harabagiu. 2006. Enhanced inter- active question answering with 
conditional random fields. In Proceedings of IQA.
[21] R. Hobbs. 2002. From question-answering to information-seeking dialogs.
[22] Jönsson and M. Merkel. 2003. Some issues in dialogue-based question-answering. 
In Working Notes from AAAI Spring Symposium, Stanford.
[23] Kato, J. Fukumoto, F.Masui, and N. Kando. 2006. Woz simulation of interactive 
question answering. In Proceedings of IQA.
[24] Greig, J. (2018). Google's Dialogflow Enterprise helps businesses create AI-powered 
chatbots. Available at, https://www.techrepublic.com/article/google-officially-unveilschatbot-dialogflow-enterprise/
[25] Herriman, M, Meer, E., Rosin, R., Lee, V., Washington, V, & Volpp, K. (2020). Asked 
and Answered: Building a Chatbot to Address COVID-19-Related Concerns. NEJM Catalyst 
Innovations in Care Delivery. DOI: 10.1056/CAT.20.0230.
[26] Huang, J., Zhou, M., & Yang, D. (2007). Extracting Chatbot Knowledge from Online 
Discussion Forums. In IJCAI(Vol. 7, pp. 423-428).
[27] Kaplan, A. M., & Haenlein, M. (2019). Siri, Siri, in my hand: Who’s the fairest in the 
land? On the interpretations, illustrations, and implications of artificial intelligence. Business 
Horizons, 62(1), 15–25.
[28] Maroengsit, W., Piyakulpinyo, T., Phonyiam, K., Pongnumkul, S., Chaovalit, P., & 
Theeramunkong, T. (2019, March). A Survey on Evaluation Methods for Chatbots. In 
Proceedings of the 2019 7th International Conference on Information and Education 
Technology (pp. 111-119).
[29] Martin, A., Nateqi, J., Gruarin, S., Munsch, N., Abdarahmane, I., & Knapp, B. (2020). 
An artificial intelligence-based firstline defence against COVID-19: digitally screening 
citizens for risks via a chatbot. bioRxiv.
[30] Paul, M. S. (2018). How to build a chatbot with Dialog flow. Available at 
https://medium.com/swlh/how-to-build-a-chatbotwith-dialog-flow-chapter-1-introductionab880c3428b5
